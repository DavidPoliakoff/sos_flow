\todofilebegin{020\_intro\_motivation.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NOTE: no \IEEEPARstart

\section{Introduction}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivation}

\todo[inline]{explain terms: cores, nodes, loosely-coupled, etc.}
\todo[inline]{set up the necessity for a new performance model....  }
The designs of SOS and its semantic performance model reflect many of
the new challenges introduced by exascale HPC clusters, and the
programming models that come with them.

One such challenge is the high cost of synchronization and
coordination across the vastly increased number of cores which might
be allocated to a single job.

Low-cost communication and synchronization between nodes is a luxury
that the HPC researcher can no longer rely on moving forward. There
are simply too many nodes! Information moving near the speed of light,
sent to issue coordinating instructions to all of the processes
running on an exascale cluster, would introduce such delays and
``bubbles'' in the computation that the simulation may as well have
been run on a present-generation petascale
machine. \todo[inline]{cite} Solutions like task-based runtime
environments (HPX, charm++, etc.)  are being developed to facilitate
general-purpose programming models that will work on both present day
petascale machines, and future exascale architectures. These
architectures forgo fixed synchronous behaviors, but also remove many
of the guarantees that formed the basis for much of the performance
models and evaluation techniques in our current paradigm.

Intelligent modern processors have been able to do branch-prediction,
out-of-order instruction execution, dynamic clock scaling, data
pre-fetch, and more, each of which introduce emergent deviations from
the a priori provable behavior characteristics of any given piece of
software. For most purposes other than optimizing low-level
infrastructure codes, this ``jitter'' was indistinguishable from
normal background noise.

Systems programmers, however, lamented this lack of predictive power
over fine-grained behavior, especially considering the potential
meaninglessness of any given observed
deviation. \todo[inline]{cite:schultz on fans/turbo mode/etc.}  This
problem only grows worse in proportion to the size and complexity of
a cluster, and the consumption of shared resources by the various tasks
that are executing concurrently.  Differences in available power, core
clock rates, communication times, filesystem latency, and more, within
the same job, each can confound the observed performance data at any
point and overall.

Performance research is classically concerned with decreasing the
resource consumption and compute time required by low-level components
and libraries that are used when persuing answers to higher-level
scientific questions. For example: In order to validate some
percentage increase in some code's performance, it will be necessary
to show that the performance increase was observed across a large
number of runs and assorted hardware allocations, especially if it is
the case that a particular HPC cluster (when in an overall state
similar to the one it was in during those workflow runs) has a history
of performance variability with any statistical significance relative
to the observed performance gain. When it comes to the behavior of
codes at extreme scales, accuracy validation using traditional models
of component-based performance analysis will become cost prohibitive
in both allocation consumption and developer time.

How can ``performance'' mean anything intelligible at all in the
exascale world, when the fine-grained code-sharpening it entails is
now no longer observable or possibly converged on?  There is a clear
need for a new model for performance, and yet, even in cases where
nothing can be done to influence the variations in lower-level
performance metrics, it is important to recognize that performance
variability is present and to \textit{attempt to both quantify it and
render reasonable attributions of its source[s]}. There are tractible
concerns (demonstrating sensitivity to variance) and inherently
intractible concerns (perfectly controlling variance across runs) that
the performance model should be designed to represent and that the
runtime middleware should be savvy to in its analytics, feedback, and
control mechanisms.

There are many motivations to observe HPC application performance in
the ways described in this paper:
\begin{itemize}
\item Attribution of blame in a shared execution environment
\item Compare job runs across various platforms
\item Compare performance data between runs that were parameterized differently.
\item The ability to support orthognoal perspectives:
  \begin{itemize}
     \item Researchers may want to know how their simulation code is
       performing at various scales, document its interactions with other
       codes, and be able to profile their runs for purposes of
       reproducibility and verification of the validity of their science.
       They want to maximize their consumption of resources, exclusively
       benefitting their own interests and compute budget.
     \item System administrators want to get the most value out of the
       hardware they support, in addition to providing optimal
       outcomes for the researchers they support. They want to fairly
       share the resources between all users, and consume as little
       system resources as necessary for the administrative software
       stack to facilitate a useful and stable HPC platform for their users.
  \end{itemize}
\end{itemize}




\todofileend{020\_intro\_motivation.tex}

