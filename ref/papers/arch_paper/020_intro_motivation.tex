%\todofilebegin{020\_intro\_motivation.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NOTE: no \IEEEPARstart

%%%%%
\section{Introduction}
Modern clusters for parallel computing are complex environments and
the high-performance applications that run on them do so often with
little insight about their or the system's behavior.
%
This is not to say that information is unavailable.  After all,
sophisticated parallel measurement systems can capture performance and
power data for characterization, analysis, and tuning purposes, but
the infrastructure for observation of these systems is not intended
for general use.
%
Rather, it is specialized for certain types of performance information
and typically does not allow online processing.
%
Other information sources of interest might include the
operating system (OS), network hardware, runtime services, or the
parallel application itself.
%
Cluster monitoring systems like Ganglia \cite{massie2004ganglia} or
Nagios \cite{katsaros2011building} collect and process data about the
performance and health of cluster-wide resources, but do not provide
sufficient fidelity to capture the complex interplay between
applications competing for shared resources.
%
In contrast, the Lightweight Distributed Metric Service
\cite{agelastos2014lightweight} (LDMS) attempts to capture system data
continuously to obtain insight into behavioral characteristics of
individual applications with respect to their resource utilization.
%
However, neither of these provides a framework that can be configured
with and used directly by the application, nor allow for semantic
encoding of multiple observation sources.
%%%%%%%

%%%%%%%
Our general interest is in parallel application monitoring: the
observation, introspection, and possible adaptation of an application
during its execution.
%
Application monitoring has several requirements.  Because information
could come from different sources and be used for different purposes,
it is important to have a flexible means for information to be
provided from both the application and the system environment.
%
Because information will need to be processed online, it is important
to enable analysis in situ with the application.
%
Because analysis can result in application feedback, query and control
interfaces are required, again to both the application and the system.
%
There exists no general purpose infrastructure that can be programmed,
configured, and launched with the application to provide the
integrated observation, introspection, and adaptation support
required.
%%%%%

%%%%%
This paper presents the \textit{Scalable Observation System (SOS)} for
integrated application monitoring.
%
The SOS design emphasizes a semantic data model with distributed
information management and structured query and access.
%
A dynamic database architecture is used in SOS to support aggregation
of streaming observations from multiple sources.
%
SOS provides interfaces for sources of information to encode data,
metadata, and semantic context.
%
Interfaces are also provided for in situ analytics to acquire
information and send back results for application actuators.
%
SOS launches with the application, runs along side it, and can acquire
its own resources for scalable data collection and processing.
%
The primary objectives of SOS are flexibility, scalability, and
programmability.
%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Limitated Perspective of Classic Performance Models}

%%%%%
The design of SOS and its Semantic Performance Model reflect changing
interests that have come into focus during the drive to exascale HPC
clusters, and the programming challenges at that scale.
%
One such challenge that is representative of the general experience is
the high cost of synchronization and coordination across the vastly
increased number of cores which might be allocated to a single
job.
%
Many classic algorithms and data structures are proving unweildy at
scale, and so too are the tools and methodologies that have have
defined performance research for the last quarter century.
%%%%%

%%%%%
Seemingly instant coordination and synchronization between nodes is a
luxury that the HPC researcher can no longer rely on moving
forward.
%
There are simply too many nodes! Information moving near the
speed of light, sent to issue coordinating instructions to all of the
processes running on an exascale cluster, would introduce such delays
and ``bubbles'' in the computation that the simulation may as well
have been run on a present-generation petascale machine.
%
Computing resources are either too abstracted from the machine,
heterogenous, distal, or failure prone to be dependent on constantly
tightly-coupled behavior -- precisely the sort of behavior HPC
scientists have been optimizing towards for years.
%%%%%

%%%%%
Incremental solutions using loosely-coupled asynchronous task-based
runtime environments \cite{kaiser2014hpx} like HPX (Or alternately:
Charm++, etc.) are being developed to facilitate general-purpose
programming models that will work on both present day petascale
machines, and future exascale architectures.
%
These architectures forgo fixed synchronous behaviors, but also remove
many of the guarantees that formed the basis for much of the
performance models and evaluation techniques in our current paradigm.
%
They cannot be easily reasoned about using any of our models without
appearing terribly inefficient or hopelessly opaqe to more than
superficial analysis.
%%%%%

%%%%%
This problem is not entirely new.
%%%%%

%%%%%
Intelligent modern processors have been able to do branch-prediction,
out-of-order instruction execution, dynamic clock scaling, data
pre-fetch, and more, each of which introduce emergent deviations from
the a priori provable behavior characteristics of any given piece of
software.
%
For common application software scenarios like browsing the web, this
\textit{jitter} was indistinguishable from normal background
noise.
%
Losing our predictive power over fine-grained behavior has not been
without cost for those working to optimize deep infrastructure codes,
especially considering the potential meaninglessness of any given
observed decreased or improved performance.
%
The methodically-gnawing problem of \textit{resolution decay} only
grows worse in proportion to the size and complexity of a computer and
the consumption of shared resources by the various tasks that are
executing concurrently.
%
On even a reasonably small cluster of basic compute nodes, marked
differences in available power, core clock rates, communication times,
filesystem latency, and more, encountered even between units of a
single parallel task.
%
Any given source of variability by itself can confound the observed
performance data at any sampled point and foul up the overall view.
%%%%%

%%%%%
Performance research is classically concerned with decreasing the
resource consumption and compute time required by lower-level
components and libraries that are used when computing answers to
higher-level scientific questions.
%
When there is a lot of noise in the information due to unpredictable
interference, the only way to validate performance increases is to
perform a large number of runs.
%
When the variation in performance is only observable at large scales,
the tests have to be repeated at large scales, and so the classic
models for performance fail again to be useful, as statistically
significant validation of code characteristics becomes
cost-prohibitive to making any progress.
%%%%%

%%%%%
Does \textit{performance}, as it has been understood, mean anything
intelligible at all in the exascale world, when the fine-grained
code-sharpening it entails is now no longer practically observable and
cannot possibly be converged on?
%
How do we assess the coarse-grained and state-contingent performance
gains that \textit{are} observable?
%%%%%

%%%%%
\textbf{There is a clear need for a new model for performance.}
%%%%%

%%%%%
There remain common cases where nothing can be done to influence the
fine-grained variations in lower-level performance metrics, yet it is
still important to recognize and capture the fact that
\textit{performance variability is present} and to \textit{attempt to
  both quantify it and render reasonable attributions of its
  source[s]}.
%
There are tractible concerns for classic performance
analysis, such as demonstrating sensitivity to variance.
%
There are \textit{inherently intractible concerns} such as perfectly
controlling variance across runs.
%%%%%

%%%%%
Any new performance model should be designed with awareness of such
distinctions so that the language used to discuss performance, the
runtime environment, and the integrated middleware can be all be apt
to our purposes, fit for the task we're undertaking, and efficient in
our analytics, feedback, and control mechanisms.
%
The new model should effectively stand in for the old and serve the
pursuit of the present-possible goals while converging on the
approaching-elusive ones.
%%%%%

%%%%%
We now look at our proposal for this new performance model, the
Scalable Observation System, and a working implementation of it
as a programmable middleware layer: SOSflow.
%%%%%

%\todofileend{020\_intro\_motivation.tex}

